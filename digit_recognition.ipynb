{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY7gn+BszLBkSSoj7/uweI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saithepaithewhyyy/saipraneeth_aimlbcs_210900/blob/main/digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten digit recognition using numpy\n",
        "\n",
        "In this notebook, i have built a nn model using numpy and built the model from the ground up that predicts what thye written digit is\n",
        "\n",
        "The model uses the standard MNIST dataset to train and predict"
      ],
      "metadata": {
        "id": "2X0BPRoIuw3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "vRkbBEnB4Fgf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing and storing the required dataset\n",
        "\n",
        "from keras.datasets import mnist \n",
        "(X,Y), (X_test, Y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yBSa8RBuWo1",
        "outputId": "f84a1e52-e008-424b-c502-a1cd51d0a7e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset into training and validation sets\n",
        "rand=np.arange(60000)\n",
        "np.random.shuffle(rand)\n",
        "train_no=rand[:50000]\n",
        "\n",
        "val_no=np.setdiff1d(rand,train_no)\n",
        "\n",
        "X_train,X_val=X[train_no,:,:],X[val_no,:,:]\n",
        "Y_train,Y_val=Y[train_no],Y[val_no]"
      ],
      "metadata": {
        "id": "mLtLgTfju1qN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the sigmoid function and its derivative \n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(np.exp(-x)+1)    \n",
        "\n",
        "def d_sigmoid(x):\n",
        "    return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
        "\n",
        "#defining the softmax function and its derivative\n",
        "\n",
        "def softmax(x):\n",
        "    exp_element=np.exp(x-x.max())\n",
        "    return exp_element/np.sum(exp_element,axis=0)\n",
        "def d_softmax(x):\n",
        "    exp_element=np.exp(x-x.max())\n",
        "    return exp_element/np.sum(exp_element,axis=0)*(1-exp_element/np.sum(exp_element,axis=0))"
      ],
      "metadata": {
        "id": "6ttEMVLQvXeo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mat function takes matrix size and returns a matrix with randomized weights\n",
        "def mat(x,y):\n",
        "    layer=np.random.uniform(-1.,1.,size=(x,y))/np.sqrt(x*y)\n",
        "    return layer.astype(np.float32)\n",
        "\n",
        "np.random.seed(42)\n",
        "l1=mat(28*28,128) # matrix of size 784*128 corresponding to the first layer\n",
        "l2=mat(128,10) # matrix of size 128*10 corresponding to the output layer"
      ],
      "metadata": {
        "id": "Fjs8JFz3vMp2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward and backward propogation\n",
        "\n",
        "def forwardbackward(x,y):\n",
        "    targets = np.zeros((len(y),10), np.float32)\n",
        "    targets[range(targets.shape[0]),y] = 1\n",
        "    \n",
        "    \n",
        "    #input matrix is multiplied with the weights and passed through the sigmoid functions\n",
        "    x_l1=x.dot(l1)\n",
        "    x_sigmoid=sigmoid(x_l1)\n",
        "    x_l2=x_sigmoid.dot(l2)\n",
        "    out=softmax(x_l2)\n",
        "   \n",
        "    #calculating errors and updating l2\n",
        "    error=2*(out-targets)/out.shape[0]*d_softmax(x_l2)\n",
        "    update_l2=x_sigmoid.T@error\n",
        "    \n",
        "    #calculating errors and updating l1\n",
        "    error=((l2).dot(error.T)).T*d_sigmoid(x_l1)\n",
        "    update_l1=x.T@error\n",
        "\n",
        "    return out,update_l1,update_l2 "
      ],
      "metadata": {
        "id": "vLlxppM5vgsq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since gradient descent would take too long, sgd on a size of 128 with learning rate 0f 0.001\n",
        "\n",
        "epochs=10000\n",
        "lr=0.001\n",
        "batch=128\n",
        "\n",
        "losses,accuracies,val_accuracies=[],[],[]\n",
        "\n",
        "for i in range(epochs):\n",
        "    #creating a random sample with size 128\n",
        "    sample=np.random.randint(0,X_train.shape[0],size=(batch))\n",
        "    x=X_train[sample].reshape((-1,28*28))\n",
        "    y=Y_train[sample]\n",
        " \n",
        "\n",
        "    out,update_l1,update_l2=forwardbackward(x,y)\n",
        "    #calculating the accuracy and adding it to the accuracies array\n",
        "    #category stores the most likely number \n",
        "    category=np.argmax(out,axis=1)\n",
        "    accuracy=(category==y).mean()\n",
        "    accuracies.append(accuracy)\n",
        "    #calculating the loss using mean squared error and adding it to the losses array\n",
        "    loss=((category-y)**2).mean()\n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    #updating the weights\n",
        "    l1=l1-lr*update_l1\n",
        "    l2=l2-lr*update_l2\n",
        "    \n",
        "    #printing out the data\n",
        "    if(i%100==0):    \n",
        "        X_val=X_val.reshape((-1,28*28))\n",
        "        val_out=np.argmax(softmax(sigmoid(X_val.dot(l1)).dot(l2)),axis=1)\n",
        "        val_acc=(val_out==Y_val).mean()\n",
        "        val_accuracies.append(val_acc.item())\n",
        "    if(i%500==0): print(f'For {i}th epoch: train accuracy: {accuracy:.3f} | validation accuracy:{val_acc:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co-Llmo3wEdt",
        "outputId": "af7db141-535e-4b43-9175-227ee35745cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 0th epoch: train accuracy: 0.047 | validation accuracy:0.072\n",
            "For 500th epoch: train accuracy: 0.672 | validation accuracy:0.655\n",
            "For 1000th epoch: train accuracy: 0.781 | validation accuracy:0.744\n",
            "For 1500th epoch: train accuracy: 0.734 | validation accuracy:0.769\n",
            "For 2000th epoch: train accuracy: 0.844 | validation accuracy:0.784\n",
            "For 2500th epoch: train accuracy: 0.789 | validation accuracy:0.794\n",
            "For 3000th epoch: train accuracy: 0.781 | validation accuracy:0.801\n",
            "For 3500th epoch: train accuracy: 0.836 | validation accuracy:0.807\n",
            "For 4000th epoch: train accuracy: 0.797 | validation accuracy:0.812\n",
            "For 4500th epoch: train accuracy: 0.828 | validation accuracy:0.815\n",
            "For 5000th epoch: train accuracy: 0.828 | validation accuracy:0.817\n",
            "For 5500th epoch: train accuracy: 0.812 | validation accuracy:0.820\n",
            "For 6000th epoch: train accuracy: 0.844 | validation accuracy:0.822\n",
            "For 6500th epoch: train accuracy: 0.781 | validation accuracy:0.822\n",
            "For 7000th epoch: train accuracy: 0.820 | validation accuracy:0.822\n",
            "For 7500th epoch: train accuracy: 0.812 | validation accuracy:0.824\n",
            "For 8000th epoch: train accuracy: 0.891 | validation accuracy:0.824\n",
            "For 8500th epoch: train accuracy: 0.859 | validation accuracy:0.824\n",
            "For 9000th epoch: train accuracy: 0.859 | validation accuracy:0.824\n",
            "For 9500th epoch: train accuracy: 0.812 | validation accuracy:0.824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IblVJ7ICzjI2",
        "outputId": "f716e43f-a721-46e2-822a-dce7e0e13d61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.25"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8am5L7cOm_hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnqVIgu-zpEo",
        "outputId": "65e49038-03fb-4580-bd49-82468a8e3a01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.43"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# As can be seen, the accuracy is pretty low. This can be improved if more complex functions are used for activation and loss"
      ],
      "metadata": {
        "id": "EGedHUsPmwtn"
      }
    }
  ]
}